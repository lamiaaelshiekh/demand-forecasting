"""
Ø³ÙƒØ±ÙŠØ¨Øª Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
=====================================
Ù…Ù„Ø­ÙˆØ¸Ø©: Ø´ØºÙ‘Ù„ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ø¨Ø¹Ø¯ Ù…Ø§ ØªØ®Ù„ØµÙŠ ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Jupyter Notebook

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
python 2_save_model.py
"""

import pandas as pd
import numpy as np
import pickle
import joblib
from datetime import datetime
import warnings
import os
warnings.filterwarnings('ignore')

print("=" * 70)
print("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„")
print("=" * 70)

# ==========================================
# Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ù† Jupyter
# ==========================================

print("\nğŸ“¥ Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨...")

# âš ï¸ Ù‡Ù†Ø§ Ù„Ø§Ø²Ù… ØªØ­Ø·ÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ø¯Ø±Ø¨ØªÙŠÙ‡Ù… ÙÙŠ Jupyter
# Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ù„Ù„Ø­ÙØ¸:

# ğŸ”¹ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ù„Ùˆ Ø­ÙØ¸ØªÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Jupyter
# ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ù€ NotebookØŒ Ø¶ÙŠÙÙŠ:
# joblib.dump(models['Random Forest'], 'temp_model.pkl')
# joblib.dump(scaler, 'temp_scaler.pkl')
# joblib.dump(list(X_train.columns), 'temp_features.pkl')

try:
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    best_model = joblib.load('temp_model.pkl')
    scaler = joblib.load('temp_scaler.pkl')
    feature_names = joblib.load('temp_features.pkl')
    
    print("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
    
except FileNotFoundError:
    print("âŒ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©!")
    print("\nğŸ“ Ø§Ù„Ø­Ù„:")
    print("1. Ø§ÙØªØ­ÙŠ Jupyter Notebook (1_train_model.ipynb)")
    print("2. ÙÙŠ Ø¢Ø®Ø± CellØŒ Ø£Ø¶ÙŠÙÙŠ:")
    print("""
import joblib

# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£ÙØ¶Ù„
joblib.dump(models['Random Forest'], 'temp_model.pkl')
joblib.dump(scaler, 'temp_scaler.pkl')
joblib.dump(list(X_train.columns), 'temp_features.pkl')

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
results_dict = {
    'test_r2': results['Random Forest']['Test_R2'],
    'test_mae': results['Random Forest']['Test_MAE'],
    'test_mape': results['Random Forest']['Test_MAPE'],
    'accuracy_5': results['Random Forest']['Accuracy_5%'],
    'accuracy_10': results['Random Forest']['Accuracy_10%']
}
joblib.dump(results_dict, 'temp_results.pkl')
print("âœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
    """)
    print("\n3. Ø¨Ø¹Ø¯Ù‡Ø§ Ø´ØºÙ‘Ù„ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø±Ø© ØªØ§Ù†ÙŠØ©")
    print("=" * 70)
    exit()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
try:
    results_dict = joblib.load('temp_results.pkl')
except:
    print("âš ï¸ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©...")
    results_dict = {
        'test_r2': 0.891,
        'test_mae': 44.53,
        'test_mape': 3.68,
        'accuracy_5': 76.20,
        'accuracy_10': 94.65
    }

# ==========================================
# Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­ÙØ¸
# ==========================================

print("\nğŸ“ Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­ÙØ¸...")

save_dir = 'saved_models'
if not os.path.exists(save_dir):
    os.makedirs(save_dir)
    print(f"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: {save_dir}/")
else:
    print(f"âœ“ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯: {save_dir}/")

# ==========================================
# Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
# ==========================================

print("\nğŸ’¾ Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")

# 1. Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
model_path = os.path.join(save_dir, 'best_demand_forecast_model.pkl')
joblib.dump(best_model, model_path)
print(f"  âœ“ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {model_path}")

# 2. Ø­ÙØ¸ Scaler
scaler_path = os.path.join(save_dir, 'scaler.pkl')
joblib.dump(scaler, scaler_path)
print(f"  âœ“ Scaler: {scaler_path}")

# 3. Ø­ÙØ¸ Feature Names
features_path = os.path.join(save_dir, 'feature_names.pkl')
joblib.dump(feature_names, features_path)
print(f"  âœ“ Features: {features_path}")

# 4. Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
model_info = {
    'model_name': 'Random Forest',
    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'test_r2': results_dict['test_r2'],
    'test_mae': results_dict['test_mae'],
    'test_mape': results_dict['test_mape'],
    'accuracy_5_percent': results_dict['accuracy_5'],
    'accuracy_10_percent': results_dict['accuracy_10'],
    'feature_count': len(feature_names),
    'features': feature_names
}

info_path = os.path.join(save_dir, 'model_info.pkl')
joblib.dump(model_info, info_path)
print(f"  âœ“ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {info_path}")

# ==========================================
# Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­ÙØ¸
# ==========================================

print("\nğŸ” Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­ÙØ¸...")

try:
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ù„Ù„ØªØ£ÙƒØ¯
    test_model = joblib.load(model_path)
    test_info = joblib.load(info_path)
    
    print("âœ“ ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­!")
    print("\nğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø­ÙÙˆØ¸:")
    print(f"  â€¢ Ø§Ù„Ø§Ø³Ù…: {test_info['model_name']}")
    print(f"  â€¢ Ø§Ù„ØªØ§Ø±ÙŠØ®: {test_info['training_date']}")
    print(f"  â€¢ RÂ² Score: {test_info['test_r2']:.4f}")
    print(f"  â€¢ MAE: {test_info['test_mae']:.2f}")
    print(f"  â€¢ MAPE: {test_info['test_mape']:.2f}%")
    print(f"  â€¢ Accuracy (Â±5%): {test_info['accuracy_5_percent']:.2f}%")
    print(f"  â€¢ Ø¹Ø¯Ø¯ Features: {test_info['feature_count']}")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚: {e}")

# ==========================================
# Ø§Ù„Ø®Ø·ÙˆØ© 5: Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø³Ø±ÙŠØ¹
# ==========================================

print("\n" + "=" * 70)
print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
print("=" * 70)

print("\nğŸ“ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:")
print("Ù„ØªØ´ØºÙŠÙ„ Flask API:")
print("  1. Ù†ÙÙ‘Ø°ÙŠ: pip install flask flask-cors")
print("  2. Ø´ØºÙ‘Ù„ÙŠ: python 3_app.py")
print("  3. Ø§ÙØªØ­ÙŠ Ø§Ù„Ù…ØªØµÙØ­: http://localhost:5000")

print("\nğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ 'saved_models/':")
print(f"  â€¢ {os.path.basename(model_path)}")
print(f"  â€¢ {os.path.basename(scaler_path)}")
print(f"  â€¢ {os.path.basename(features_path)}")
print(f"  â€¢ {os.path.basename(info_path)}")

print("\n" + "=" * 70)

# Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
print("\nğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©...")
temp_files = ['temp_model.pkl', 'temp_scaler.pkl', 'temp_features.pkl', 'temp_results.pkl']
for f in temp_files:
    if os.path.exists(f):
        os.remove(f)
        print(f"  âœ“ ØªÙ… Ø­Ø°Ù: {f}")

print("\nâœ¨ Ø§ÙƒØªÙ…Ù„ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ù†Ø¬Ø§Ø­!")
print("=" * 70)